diff --git a/config.py b/config.py
index 9db2bb3..bd454d6 100644
--- a/config.py
+++ b/config.py
@@ -9,15 +9,3 @@ cfg['model'] = {
     'fem_channel': 32,
     'block_num': 9,
 }
-cfg['data'] = {
-    'data_dir': '/home/ymshi/Face/data/MBLLEN_dataset',
-    'batch_size': 16,
-    'num_workers': 4,
-    'dark_or_low': 'lowlight'
-}
-cfg['trainer'] = {
-    'gpus':[0,1],
-    'precision': 32,
-    'max_epochs': 80,
-    'monitor': 'val_loss'
-}
\ No newline at end of file
diff --git a/main.py b/main.py
index df7af1e..04f54c9 100644
--- a/main.py
+++ b/main.py
@@ -1,10 +1,10 @@
 import torch
 from torch.nn import functional as F
 from torch.utils.data import DataLoader
-from torchvision import transforms
+#from torchvision import transforms
 
 from pytorch_lightning import LightningModule, LightningDataModule, Trainer
-from pytorch_lightning.plugins import DDPPlugin
+#from pytorch_lightning.plugins import DDPPlugin
 from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
 
 from utils.model import MBLLEN
@@ -53,7 +53,7 @@ class Data(LightningDataModule):
         self.batch_size = data_cfg['batch_size']
         self.num_workers = data_cfg['num_workers']
         self.dark_or_low = data_cfg['dark_or_low']
-        self.transform = transforms.Compose([transforms.ToTensor()])
+        #self.transform = transforms.Compose([transforms.ToTensor()])
 
     def prepare_data(self):
         pass
@@ -95,7 +95,6 @@ if __name__ == '__main__':
                       max_epochs=cfg['trainer']['max_epochs'], 
                       accelerator='ddp', 
                       precision=cfg['trainer']['precision'],
-                      progress_bar_refresh_rate=1, 
-                      plugins=DDPPlugin(find_unused_parameters=False), 
+                      progress_bar_refresh_rate=1,  
                       callbacks=[ModelCheckpoint(monitor=cfg['trainer']['monitor']), LearningRateMonitor(logging_interval='step')])
     trainer.fit(model, data)
\ No newline at end of file
