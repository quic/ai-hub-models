# ---------------------------------------------------------------------
# Copyright (c) 2024 Qualcomm Innovation Center, Inc. All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# ---------------------------------------------------------------------
from __future__ import annotations

import logging
from contextlib import contextmanager
from typing import Tuple

import numpy as np
import torch


def flatten(obj):
    """Flatten nested list or tuple"""
    tgt_type = (list, tuple)  # targeted types
    flattened_list = []
    for item in obj:
        if isinstance(item, tgt_type):
            flattened_list.extend(flatten(item))
        else:
            flattened_list.append(item)
    return flattened_list


@contextmanager
def suppress_warnings():
    """
    Suppresses warning generated by block called within.
    This is helpful to supress warning when one loads part of the model and
    sub-module throws warning which should be ignored for clean UX.
    """

    old_level = logging.root.manager.disable
    logging.disable(logging.WARNING)
    try:
        yield
    finally:
        logging.disable(old_level)


class TorchNumpyAdapter:
    def __init__(self, base_model: torch.jit.ScriptModule | torch.nn.Module):
        """
        Wraps torch models to use numpy input / outputs
        """
        assert isinstance(base_model, (torch.jit.ScriptModule, torch.nn.Module))
        self.base_model = base_model

    def __call__(self, *args) -> Tuple[np.ndarray, ...]:
        inp = []
        for t in args:
            if not isinstance(t, np.ndarray):
                inp.append(t)
            else:
                inp.append(torch.from_numpy(t))
        input_data = tuple(inp)
        res = self.base_model(*input_data)
        if isinstance(res, torch.Tensor):
            output = res.detach().numpy()
        else:
            output = tuple(t.detach().numpy() for t in flatten(res))
        if isinstance(output, tuple) and len(output) == 1:
            return output[0]
        return output
