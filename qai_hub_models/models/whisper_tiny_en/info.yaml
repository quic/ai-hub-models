name: Whisper-Tiny-En
# id must match with the model dir name in qai_hub_models
id: whisper_tiny_en
status: public
headline: Automatic speech recognition (ASR) model for English transcription
  as well as translation.
domain: Audio
description: OpenAIâ€™s Whisper ASR (Automatic Speech Recognition) model is a state-of-the-art system designed for transcribing spoken language into written text. It exhibits robust performance in realistic, noisy environments, making it highly reliable for real-world applications. Specifically, it excels in long-form transcription, capable of accurately transcribing audio clips up to 30 seconds long. Time to the first token is the encoder's latency, while time to each additional token is decoder's latency, where we assume a mean decoded length specified below.
use_case: Speech Recognition
tags:
  - foundation
research_paper: https://cdn.openai.com/papers/whisper.pdf
research_paper_title: Robust Speech Recognition via Large-Scale Weak Supervision
license: https://github.com/openai/whisper/blob/main/LICENSE
deploy_license: https://qaihub-public-assets.s3.us-west-2.amazonaws.com/qai-hub-models/Qualcomm+AI+Hub+Proprietary+License.pdf
source_repo: https://github.com/openai/whisper/tree/main
technical_details:
  Model checkpoint: tiny.en
  Input resolution: 80x3000 (30 seconds audio)
  Mean decoded sequence length: 112 tokens
  Number of parameters (WhisperEncoder): 9.39M
  Model size (WhisperEncoder): 35.9 MB
  Number of parameters (WhisperDecoder): 28.2M
  Model size (WhisperDecoder): 108 MB
applicable_scenarios:
  - Smart Home
  - Accessibility
related_models:
  - whisper_base_en
  - whisper_small_en
  - huggingface_wavlm_base_plus
form_factors:
  - Phone
  - Tablet
  - IoT
has_static_banner: true
has_animated_banner: true
license_type: mit
deploy_license_type: AI Model Hub License
dataset: []
