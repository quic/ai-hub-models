name: PLaMo-1B
id: plamo_1b_quantized
status: public
headline: State-of-the-art large language model useful on a variety of language
  understanding and generation tasks.
domain: Generative AI
description: PLaMo-1B is the first small language model (SLM) in the PLaMo™ Lite series from Preferred Networks (PFN), designed to power AI applications for edge devices including mobile, automotive, and robots across various industrial sectors. This model builds on the advancements of PLaMo-100B, a 100-billion parameter large language model (LLM) developed from the ground up by PFN’s subsidiary Preferred Elements (PFE). Leveraging high-quality Japanese and English text data generated by PLaMo-100B, PLaMo-1B has been pre-trained on a total of 4 trillion tokens. As a result, it delivers exceptional performance in Japanese benchmarks, outperforming other SLMs with similar parameter sizes. In evaluations such as Jaster 0-shot and 4-shot, PLaMo-1B has demonstrated performance on par with larger LLMs, making it a highly efficient solution for edge-based AI tasks.
model_maker_id: preferred-networks
use_case: Text Generation
tags:
  - llm
  - generative-ai
  - quantized
technical_details:
  Input sequence length for Prompt Processor: 128
  Context length: 4096
  Number of parameters: 1B
  Precision: w4a16 + w8a16 (few layers)
  Use: Initiate conversation with prompt-processor and then token generator for subsequent iterations.
  Minimum QNN SDK version required: 2.27.7
  Supported languages: Japanese and English.
  TTFT: Time To First Token is the time it takes to generate the first response token. This is expressed as a range because it varies based on the length of the prompt. The lower bound is for a short prompt (up to 128 tokens, i.e., one iteration of the prompt processor) and the upper bound is for a prompt using the full context length (4096 tokens).
  Response Rate: Rate of response generation after the first response token.
applicable_scenarios:
  - Dialogue
  - Content Generation
  - Customer Support
related_models: []
form_factors:
  - Phone
  - Tablet
has_static_banner: true
has_animated_banner: false
license_type: 'other'
dataset: []
model_type_llm: true
restrict_model_sharing: true
llm_details:
  call_to_action: 'contact_for_purchase'
