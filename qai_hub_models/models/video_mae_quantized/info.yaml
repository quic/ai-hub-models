name: Video-MAE-Quantized
# id must match with the model dir name in qai_hub_models
id: video_mae_quantized
status: public
headline: Sports and human action recognition in videos.
domain: Computer Vision
use_case: Video Classification
description: Video MAE (Masked Auto Encoder) is a network for doing video classification
  that uses the ViT (Vision Transformer) backbone.
tags:
  - backbone
  - quantized
research_paper: https://arxiv.org/abs/2203.12602
research_paper_title: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training
license: https://github.com/MCG-NJU/VideoMAE/blob/main/LICENSE
deploy_license: https://qaihub-public-assets.s3.us-west-2.amazonaws.com/qai-hub-models/Qualcomm+AI+Hub+Proprietary+License.pdf
source_repo: https://github.com/MCG-NJU/VideoMAE
technical_details:
  Model checkpoint: Kinectics-400
  Input resolution: 224x224
  Number of parameters: 87.7M
  Model size: 87.7 MB
applicable_scenarios:
  - Camera
  - Action Recognition
related_models:
  - resnet_3d
  - resnet_2plus1d
  - resnet_mixed
form_factors:
  - Phone
  - Tablet
has_static_banner: true
has_animated_banner: true
license_type: cc-by-4.0
deploy_license_type: AI Model Hub License
dataset: []
