name: Mobile-Bert-Uncased-Google
id: mobile_bert_uncased_google
status: public
headline: Language model for masked language modeling and general-purpose NLP tasks.
domain: Generative AI
description: MOBILEBERT is a lightweight BERT model designed for efficient self-supervised learning of language representations. It can be used for masked language modeling and as a backbone for various NLP tasks.
use_case: Text Generation
tags:
- backbone
applicable_scenarios:
- Text Classification
- Sentiment Analysis
- Named Entity Recognition
related_models:
- albert_base_v2_hf
form_factors:
- Phone
- Tablet
- IoT
- XR
has_static_banner: true
has_animated_banner: true
dataset: []
technical_details:
  Model checkpoint: mobile_bert_uncased_google
  Input resolution: 1x384
  Number of parameters: 25.3M
  Model size (float): 130 MB
license_type: apache-2.0
research_paper: https://arxiv.org/abs/2004.02984
research_paper_title: 'MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices'
source_repo: https://github.com/google-research/google-research/tree/master/mobilebert
license: https://github.com/google-research/google-research/blob/master/LICENSE
