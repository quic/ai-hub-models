name: Albert-Base-V2-Hf
id: albert_base_v2_hf
status: public
headline: Language model for masked language modeling and general-purpose NLP tasks.
domain: Generative AI
description: ALBERT is a lightweight BERT model designed for efficient self-supervised learning of language representations. It can be used for masked language modeling and as a backbone for various NLP tasks.
use_case: Text Generation
tags:
- backbone
applicable_scenarios:
- Text Classification
- Sentiment Analysis
- Named Entity Recognition
related_models: []
form_factors:
- Phone
- Tablet
- IoT
- XR
has_static_banner: true
has_animated_banner: true
dataset: []
technical_details:
  Model checkpoint: albert/albert-base-v2
  Input resolution: 1x384
  Number of parameters: 11.8M
  Model size (float): 43.9 MB
license_type: apache-2.0
research_paper: https://arxiv.org/abs/1909.11942
research_paper_title: 'ALBERT: A Lite BERT for Self-supervised Learning of Language Representations'
source_repo: https://github.com/google-research/albert
license: https://github.com/google-research/albert/blob/master/LICENSE
